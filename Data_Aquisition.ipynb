{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1f5d7f",
   "metadata": {},
   "source": [
    "# Smartphone Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b695ffa",
   "metadata": {},
   "source": [
    "Vishakha Joshi (22070126132)  \n",
    "Yash Chandak (22070126134)  \n",
    "Girish Mahale (23070126504)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb804773",
   "metadata": {},
   "source": [
    "GitHub Link - https://github.com/girishmahale786/smartphone-price-prediction  \n",
    "Deployment Link - https://smartphone-price-prediction.streamlit.app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658765b3",
   "metadata": {},
   "source": [
    "# Data Aquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661dd42",
   "metadata": {},
   "source": [
    "**Importing Libraries**  \n",
    "In this cell, we start by importing the necessary libraries for our project. We use BeautifulSoup for parsing HTML, Pandas for data manipulation, Requests for making HTTP requests, and other standard Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7382f1cc-5522-43c8-ae93-04127a1eea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d46ff7",
   "metadata": {},
   "source": [
    "**Function Definition - get_soup**  \n",
    "In this cell, we define a custom function called `get_soup(url)`. This function takes a URL as its input and returns a BeautifulSoup object that we can use to parse the content of a webpage. We've also added error handling to manage request exceptions and implemented a retry mechanism in case of issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6366a0b4-b134-46e8-b999-237972fe8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.content, 'html.parser')\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            time.sleep(2)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2fd51",
   "metadata": {},
   "source": [
    "**Function Definition - scrape_phone_details**  \n",
    "Here, we define another function named `scrape_phone_details(phone_url)`. This function is responsible for extracting details of a mobile phone from a given URL. It collects information such as the phone's name, price, brand, rating, and specifications. All of these details are stored in a dictionary and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19777a6-d5d6-43b8-932d-36214aa1eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_phone_details(phone_url):\n",
    "    phone_soup = get_soup(phone_url)\n",
    "\n",
    "    name = phone_soup.find('div', class_='aMaAEs').find('span', class_='B_NuCI').text.strip()\n",
    "    disc_price = phone_soup.find('div', class_='_30jeq3').text.strip()\n",
    "\n",
    "    price = disc_price\n",
    "    if phone_soup.find('div', class_='_3I9_wc'):\n",
    "        price = phone_soup.find('div', class_='_3I9_wc').text.strip()\n",
    "\n",
    "    brand = None\n",
    "    if phone_soup.find('div', class_='_1MR4o5'):\n",
    "        brand = phone_soup.find('div', class_='_1MR4o5').find_all('a')[3].text.strip()\n",
    "\n",
    "    rating = None\n",
    "    if phone_soup.find('div', class_='_3LWZlK'):\n",
    "        rating = phone_soup.find('div', class_='_3LWZlK').text.strip()\n",
    "\n",
    "    phone = {\n",
    "        'Name': name,\n",
    "        'Brand': brand,\n",
    "        'Price': price,\n",
    "        'Discounted Price': disc_price,\n",
    "        'Rating': rating\n",
    "    }\n",
    "\n",
    "    specs_table = phone_soup.find_all('table', class_='_14cfVK')\n",
    "    for spec in specs_table:\n",
    "        for tr in spec.find_all('tr'):\n",
    "            td = tr.contents\n",
    "            if len(td) > 1:\n",
    "                phone[td[0].text.strip()] = td[1].text.strip()\n",
    "\n",
    "    return phone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914ddb9",
   "metadata": {},
   "source": [
    "**Function Definition - scrape_flipkart_data**  \n",
    "In this cell, we define a function called `scrape_flipkart_data(base_url, brand_urls)`. This function is the core of our web scraping project. It scrapes data from Flipkart for various brands of mobile phones. It takes a base URL and a dictionary of brand URLs as inputs, iterates through the brand URLs, and collects information from each page. The data is then stored in a nested dictionary structure for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439d8225-ebdb-4fbc-9209-4e16d479d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_flipkart_data(base_url, brand_urls):\n",
    "    phones = {}\n",
    "    for brand, url in brand_urls.items():\n",
    "        phones[brand] = []\n",
    "\n",
    "        brand_soup = get_soup(url)\n",
    "        page_count = 0\n",
    "        if brand_soup.find('div', class_='_2MImiq'):\n",
    "            page_count = int(brand_soup.find('div', class_='_2MImiq').span.text.split()[-1])\n",
    "\n",
    "        for page in range(0, page_count + 1):\n",
    "            page_url = f'{url}&page={page + 1}'\n",
    "            page_soup = get_soup(page_url)\n",
    "            phones_list = page_soup.find_all('div', class_='_13oc-S')\n",
    "\n",
    "            for phone in phones_list:\n",
    "                phone_url = f\"{base_url}{phone.find('a')['href']}\"\n",
    "                phone_specs = scrape_phone_details(phone_url)\n",
    "                phones[brand].append(phone_specs)\n",
    "\n",
    "    return phones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e8dba",
   "metadata": {},
   "source": [
    "**Define Base URL and Brand URLs**  \n",
    "Here, we set the base URL to 'https://www.flipkart.com' and define the URLs for various smartphone brands on Flipkart. Each brand URL is specified, allowing us to focus on collecting data for specific brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622d93c4-cd49-41f0-b460-466f2c75b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.flipkart.com'\n",
    "search = f'{base_url}/search?sid=tyy%2C4io&otracker=CLP_Filters&p%5B%5D=facets.price_range.from%3D10000&p%5B%5D=facets.price_range.to%3DMax'\n",
    "apple = f'{search}&p%5B%5D=facets.brand%255B%255D%3DAPPLE'\n",
    "samsung = f'{search}&p%5B%5D=facets.brand%255B%255D%3DSAMSUNG'\n",
    "google = f'{search}&p%5B%5D=facets.brand%255B%255D%3DGoogle'\n",
    "nothing = f'{search}&p%5B%5D=facets.brand%255B%255D%3DNothing'\n",
    "asus = f'{search}&p%5B%5D=facets.brand%255B%255D%3DASUS'\n",
    "oneplus = f'{search}&p%5B%5D=facets.brand%255B%255D%3DOnePlus'\n",
    "oppo = f'{search}&p%5B%5D=facets.brand%255B%255D%3DOPPO'\n",
    "vivo = f'{search}&p%5B%5D=facets.brand%255B%255D%3Dvivo'\n",
    "mi = f'{search}&p%5B%5D=facets.brand%255B%255D%3DMi'\n",
    "redmi = f'{search}&p%5B%5D=facets.brand%255B%255D%3DREDMI'\n",
    "realme = f'{search}&p%5B%5D=facets.brand%255B%255D%3Drealme'\n",
    "poco = f'{search}&p%5B%5D=facets.brand%255B%255D%3DPOCO'\n",
    "iqoo = f'{search}&p%5B%5D=facets.brand%255B%255D%3DIQOO'\n",
    "motorola = f'{search}&p%5B%5D=facets.brand%255B%255D%3DMOTOROLA'\n",
    "\n",
    "brand_urls = {\n",
    "    'apple': apple,\n",
    "    'samsung': samsung,\n",
    "    'google': google,\n",
    "    'nothing': nothing,\n",
    "    'asus': asus,\n",
    "    'oneplus': oneplus,\n",
    "    'oppo': oppo,\n",
    "    'vivo': vivo,\n",
    "    'mi': mi,\n",
    "    'redmi': redmi,\n",
    "    'realme': realme,\n",
    "    'poco': poco,\n",
    "    'iqoo': iqoo,\n",
    "    'motorola': motorola,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31a832",
   "metadata": {},
   "source": [
    "**Scraping Data**  \n",
    "This cell is where the actual scraping happens. We call the `scrape_flipkart_data` function, passing in the base URL and the dictionary of brand URLs. The code then iterates through each brand, scrapes information from their respective pages, and stores the data in separate CSV files, one for each brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83adc77-3835-48df-bdc1-0291614bbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = scrape_flipkart_data(base_url, brand_urls)\n",
    "for brand in brand_urls.keys():\n",
    "    df = pd.DataFrame(phones[brand])\n",
    "    df.to_csv(f'data/{brand}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea05bae",
   "metadata": {},
   "source": [
    "**Combining Data from CSV Files**  \n",
    "In this final cell, we bring all the data together. We read the CSV files for each brand into Pandas DataFrames and merge them into one comprehensive DataFrame named 'phones_df.' This combined dataset is saved as a 'phones.csv' file, which we can use for further analysis, research, or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cc95be-1071-4ba9-8adf-7999dd2c1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for file in os.listdir('data/'):\n",
    "    df = pd.read_csv(f'data/{file}')\n",
    "    all_df.append(df)\n",
    "\n",
    "phones_df = pd.concat(all_df)\n",
    "phones_df.to_csv('data/phones.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
